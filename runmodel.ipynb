{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# internal imports:\n",
    "import utils.datareader as datareader\n",
    "import utils.visualizer as visualizer\n",
    "from models.transformer import *\n",
    "\n",
    "# external imports:\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafolder = './data' # folder for where the data sets are\n",
    "modelsavename = 'trafo'\n",
    "predictionsavename = 'prediction_output.csv'\n",
    "\n",
    "targets = [f'Bolt_{n+1}_Tensile' for n in range(6)]\n",
    "learning_rate = 3e-4 # optimizer\n",
    "learning_rate_annealing = 3e-5 # how much the learning rate is annealed every episode\n",
    "episodes = 50000 # how often it is iterated over the entire dataset\n",
    "inputlength = 60*4 # input sequence length\n",
    "batchsize = 50 # batch size\n",
    "save_model = 500 # episodes when the model is saved\n",
    "\n",
    "# transformer model hyperparameters:\n",
    "num_layers=6\n",
    "dropout=0.05\n",
    "no_heads=8\n",
    "hidden_size=no_heads*2*6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and scale datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, dfT = datareader.df_from_folder(datafolder)\n",
    "df, dfT, scaler = datareader.normalize_input(df, dfT)\n",
    "\n",
    "features = list(dfT.columns) # find features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove overhead data, find the nan timestamps and mask nans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove overhead:\n",
    "df = df[targets+features] \n",
    "# find nan timestamps:\n",
    "nans = np.array(df[targets].isna().product(1)) * np.arange(df.shape[0]) \n",
    "nans = nans[nans != 0]\n",
    "# mask nans:\n",
    "df = df.fillna(0)\n",
    "dfT = dfT.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    net = torch.load(datafolder+'//'+modelsavename)\n",
    "except Exception:\n",
    "    net = Network(df.shape[1], len(targets), hidden_size=hidden_size, num_layers=num_layers, dropout=dropout, no_heads=no_heads, maxlen=inputlength)\n",
    "net.train() # starting in training mode\n",
    "optim = torch.optim.Rprop(net.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_episode = 10 # which episodes to plot\n",
    "losshistory = []\n",
    "for e in range(episodes):\n",
    "    # zero gradients out:\n",
    "    net.zero_grad() \n",
    "    # sample a batch:\n",
    "    x, y = sample(df, nans, targets, inputlength, batchsize, device=net.device)\n",
    "    # predict:\n",
    "    y_pred = net(x)      \n",
    "    # calculate losses:\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    # backpropagation:\n",
    "    loss.backward()\n",
    "    optim.step()       \n",
    "    # save losses:\n",
    "    losshistory.append(float(loss.detach().cpu().numpy()))\n",
    "    # visualize losses:\n",
    "    if e % plot_episode == 0:\n",
    "        visualizer.lossplot(e+1, losshistory)\n",
    "    \n",
    "    # anneal learning rate:\n",
    "    for g in optim.param_groups:\n",
    "        g['lr'] = g['lr'] * (1 - learning_rate_annealing)\n",
    "    # save model:\n",
    "    if e % save_model == 0:\n",
    "        torch.save(net, datafolder+'//'+modelsavename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "\n",
    "x = torch.tensor(df.iloc[-inputlength:].to_numpy(), dtype=torch.float).to(net.device).unsqueeze(0)\n",
    "predictions = []\n",
    "for i in range(dfT.shape[0]):\n",
    "    # predict:\n",
    "    y_pred = net(x).detach()\n",
    "    # add to prediction container:\n",
    "    predictions.append(y_pred.cpu().numpy()[0,0])\n",
    "    # add predictions to features:\n",
    "    x_pred = torch.tensor(dfT.iloc[i], dtype=torch.float).to(net.device).unsqueeze(0).unsqueeze(0)\n",
    "    x = torch.cat(\n",
    "        (\n",
    "            x, torch.cat((x_pred, y_pred),-1)\n",
    "        ), 1\n",
    "    )[:,-inputlength:,:]\n",
    "    # print update:\n",
    "    print(f'generated {i+1}|{dfT.shape[0]}')\n",
    "predictions = np.array(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionoutput = pd.DataFrame(predictions, columns=targets, index=dfT.index) # make dataframe\n",
    "predictionoutput = datareader.rescale_output(predictionoutput, scaler) # rescale outputs\n",
    "predictionoutput = predictionoutput[~np.array(dfT.isna().product(1), dtype=bool)] # remove the missing values again\n",
    "predictionoutput.to_csv(datafolder+'//'+predictionsavename)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "148f2881cd2393bab8d79b0d26af308304489d77611745ff9c0b4e918f13d152"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('krafthack')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
